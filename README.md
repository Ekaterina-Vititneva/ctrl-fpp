# Ctrl+F++

> An AI-enhanced "Ctrl+F" for complex documents.

**Ctrl+F++** is a lightweight full-stack GenAI app that lets users upload documents (like PDFs), embed them, and ask complex questions â€” powered by a local or cloud-based LLM.

![Project](./assets/image.png)

Built with:

- ðŸ§  LangChain + Semantic vector search via pgvector (or FAISS, optional)
- ðŸ FastAPI for backend + embeddings
- âš›ï¸ React + TypeScript frontend
- âš™ï¸ LLM flexibility: switch between OpenAI (e.g., GPT-4o-mini) or local models (via Ollama)

---

---

## ðŸš€ Features

- ðŸ“„ Upload PDF documents
- ðŸ”Ž Chunk & embed content using sentence-transformers
- ðŸ’¬ Ask natural-language questions
- ðŸ”—Store vector embeddings in FAISS or pgvector
- ðŸ¤– Get answers from OpenAI or Ollama (locally run LLMs)
- ðŸ§¹ Reset knowledge base anytime

---

## ðŸ§ª Local Setup

### 1. Backend (FastAPI)

```bash
cd backend
python -m venv venv
.\venv\Scripts\Activate  # On Windows
pip install -r requirements.txt
uvicorn main:app --reload --port 8001
```

Create a .env file in backend/:

```
OPENAI_API_KEY=sk-...
LLM_PROVIDER=openai  # or ollama
```

### 2. Frontend (React + Vite)

```
cd frontend
npm install
npm run dev
```

---

## ðŸ” LLM Configuration

Set the model provider in `.env`:

| `LLM_PROVIDER` | Description                   |
| -------------- | ----------------------------- |
| `openai`       | GPT-3.5 / GPT-4o-mini via API |
| `ollama`       | Local model via Ollama        |

## ðŸ—‚ï¸ Repository Structure

```txt
ctrl-fpp/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                 # FastAPI app entry
â”‚   â”œâ”€â”€ rag.py                  # Core RAG logic (embedding, retrieval, answering)
â”‚   â”œâ”€â”€ pgvectorstore.py        # pgvector wrapper
â”‚   â”œâ”€â”€ parser.py               # PDF/text chunker
â”‚   â”œâ”€â”€ embedding_model.py      # Load and use embedding model
â”‚   â”œâ”€â”€ llm_loader.py           # Configurable LLM loader (OpenAI, Ollama, etc.)
â”‚   â”œâ”€â”€ vectorstore/            # Vector DB index + metadata
â”‚   â”œâ”€â”€ data/docs/              # Uploaded PDF files
â”‚   â””â”€â”€ .env                    # Environment variables (API keys, LLM config)
â”‚
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.tsx             # App wrapper with uploader + chat
â”‚   â”‚   â”œâ”€â”€ components/         # Upload, Ask, Reset UI
â”‚   â”‚   â””â”€â”€ api.ts              # Axios setup
â”‚   â”œâ”€â”€ vite.config.ts
â”‚   â”œâ”€â”€ index.html
â”‚   â””â”€â”€ tsconfig.json
â”‚
â”œâ”€â”€ README.md
```

```
docker compose up -d --build
```

## Project Architecture

```mermaid
flowchart TD
    subgraph Frontend
        FE["React + Vite App"]
        FE -->|API Requests| Backend
    end

    subgraph Backend
        BE["FastAPI App (Ctrl+F++)"]
        BE -->|SQL queries, embedding storage| DB[(PostgreSQL + pgvector)]
        BE -->|Prompt / Query| LLM[(LLM Provider e.g. OpenAI or Local Model)]
    end

    subgraph Database
        DB[(PostgreSQL with pgvector extension)]
    end

    subgraph Admin
        PGAdmin["pgAdmin4"]
        PGAdmin -->|Manage database| DB
    end

    FE -->|Uploads PDFs| BE
    BE -->|Embeddings + Search| DB
    FE -->|Receives Answers + Quotes| BE
```

## Running with Docker

This project provides a ready-to-use `docker-compose.yml` for easy deployment.

### 1. Requirements

- Install [Docker Desktop](https://www.docker.com/products/docker-desktop/)

---

### 2. Environment Variables

Create a `.env` file in the project root (if not already present):

```bash
OPENAI_API_KEY=""
LLM_PROVIDER=""
POSTGRES_DB=""
POSTGRES_USER=""
POSTGRES_PASSWORD=""
POSTGRES_HOST=""
POSTGRES_PORT=""

PGADMIN_DEFAULT_EMAIL=""
PGADMIN_DEFAULT_PASSWORD=""

FRONTEND_ORIGINS=""
```

3. Build and Start
   To build and run the containers:

```bash
docker compose up --build
```

`db`: PostgreSQL with pgvector extension

`backend`: FastAPI server

`frontend`: React+Vite frontend (optional, runs with --profile ui)

Frontend is optional, you can start only DB + Backend like:

```bash
docker compose up backend db
```

Or include UI:

```bash
docker compose --profile ui up
```
