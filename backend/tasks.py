from __future__ import annotations

import math
import traceback
from parser import parse_pdf_pages, chunk_pdf_pages
from embedding_model import get_embedding_with_metadata
import pgvectorstore as vectorstore
from job_registry import jobs

# Granularity knobs
BATCH_SIZE       = 1         
PARSE_WEIGHT     = 0.10       # 0Â â€“Â 0.30   of the bar
CHUNK_WEIGHT     = 0.05       # 0.30 â€“Â 0.35
EMBED_WEIGHT     = 0.80       # 0.35 â€“Â 0.95
STORE_WEIGHT     = 0.05       # 0.95 â€“Â 1.00

# Helper to map phaseâ€‘local progress (0â€‘1) â†’ global bar (0â€‘1)
def _segment(base: float, span: float, frac: float) -> float:
    return round(base + span * frac, 3)


def process_pdf(job_id: str, filename: str, file_path: str) -> None:
    """
    Parse â†’ chunk â†’ embed â†’ store, emitting fineâ€‘grained progress so the
    frontâ€‘end bar moves continuously.
    Called via:   background_tasks.add_task(process_pdf, job_id, fname, path)
    """
    try:
        # â”€â”€ 1. Parse pages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        pages = parse_pdf_pages(file_path)
        total_pages = len(pages)

        for idx, page in enumerate(pages, 1):
            jobs.update(
                job_id,
                state="parsing",
                phase=f"SeiteÂ {idx}/{total_pages}",
                progress=_segment(0.0, PARSE_WEIGHT, idx / total_pages),
            )

        # â”€â”€ 2. Chunk pages â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # 2) Chunk pages â€“ emit perâ€‘page progress
        jobs.update(job_id, state="chunking")

        chunked_pages: list[dict] = []
        pages_done = 0
        for page_dict in pages:                       # pages is the list from parsing
            chunks = chunk_pdf_pages([page_dict], chunk_size=300, overlap=50)
            chunked_pages.extend(chunks)
            pages_done += 1

            # progress: 30Â %â†’35Â % of bar (CHUNK_WEIGHT =Â 0.05)
            frac = pages_done / len(pages)
            jobs.update(
                job_id,
                phase=f"SeiteÂ {pages_done}/{len(pages)}",
                progress=_segment(PARSE_WEIGHT, CHUNK_WEIGHT, frac),
            )
        
        total_chunks = len(chunked_pages)

        # â”€â”€ 3. Embedding (batched) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        embeddings, chunk_dicts = [], []
        for done in range(0, total_chunks, BATCH_SIZE):
            batch = chunked_pages[done : done + BATCH_SIZE]
            for c in batch:
                c["source"] = filename

            e, t, s, p = get_embedding_with_metadata(batch)
            print(f"ðŸ§  Embedding batch of {len(batch)} chunks â†’ {len(e)} embeddings")

            embeddings.extend(e)
            chunk_dicts.extend(
                {"chunk": txt, "source": src, "page": pg}
                for txt, src, pg in zip(t, s, p)
            )

            done_chunks = min(done + BATCH_SIZE, total_chunks)
            jobs.update(
                job_id,
                state="embedding",
                phase=f"ChunkÂ {done_chunks}/{total_chunks}",
                progress=_segment(
                    PARSE_WEIGHT + CHUNK_WEIGHT,
                    EMBED_WEIGHT,
                    done_chunks / total_chunks,
                ),
            )

        # â”€â”€ 4. Store in Postgres â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        jobs.update(job_id, state="storing",
                    phase="SchreibeÂ DBâ€¦",
                    progress=_segment(0.95, STORE_WEIGHT, 0.0))

        vectorstore.add_embeddings(embeddings, chunk_dicts, filename)

        # â”€â”€ 5. Done â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        jobs.update(job_id, state="done", phase=None, progress=1.0)

    except Exception as exc:
        traceback.print_exc()
        jobs.update(job_id, state="error", error=str(exc), progress=1.0)
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
